{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e94e028-9098-4d66-a008-e895ac8858f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "import dgl\n",
    "\n",
    "from src import *\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e4eaca-2e0c-40f8-8501-8e1b37d03c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(feature_file='./data/feature_dict.json', reuse_rate_file='./data/reuse_rate_dict.json', output_dir='./output/', agg_type='attn', nclient=4, valid=0.2, test=0.2, dropout=0.5, random_seed=1, relu=0.2, reuse_th=0.5, batch_size=8192, embed_size=256, hidden_size=256, gnn_depth=2, max_lr=0.001, warmup=0.1, max_epoch=200, early_stop=40, device=0)\n"
     ]
    }
   ],
   "source": [
    "from argparse import ArgumentParser\n",
    "parser = ArgumentParser()\n",
    "\n",
    "import argparse\n",
    "from pprint import pprint\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Parser for model configuration\")\n",
    "\n",
    "parser.add_argument('--feature_file', type=str, default=\"./data/feature_dict.json\", help='feature json file')\n",
    "parser.add_argument('--reuse_rate_file', type=str, default=\"./data/reuse_rate_dict.json\", help='reuse rate json file')\n",
    "# parser.add_argument('--setting', type=str, required=True, help='graph learning setting: inductive/transductive')\n",
    "# parser.add_argument('--model_path', type=str, required=True, default=\"./model/\", help='model file path')\n",
    "parser.add_argument('--output_dir', type=str, default=\"./output/\", help='output path')\n",
    "parser.add_argument('--agg_type', type=str, default=\"attn\", help='aggregation type')\n",
    "parser.add_argument('--nclient', type=int, default=4, help='number of clients')\n",
    "parser.add_argument('--valid', type=float, default=0.2, help='split ratio of validation set')\n",
    "parser.add_argument('--test', type=float, default=0.2, help='split ratio of test set')\n",
    "parser.add_argument('--dropout', type=float, default=0.5, help='dropout ratio')\n",
    "parser.add_argument('--random_seed', type=int, default=1, help='random seed for initialization')\n",
    "parser.add_argument('--relu', type=float, default=0.2, help='ReLU threshold')\n",
    "parser.add_argument('--reuse_th', type=float, default=0.5, help='threshold for reuse')\n",
    "parser.add_argument('--batch_size', type=int, default=8192, help='batch size for training')\n",
    "parser.add_argument('--embed_size', type=int, default=256, help='size of the embedding layer')\n",
    "parser.add_argument('--hidden_size', type=int, default=256, help='size of the hidden layer')\n",
    "parser.add_argument('--gnn_depth', type=int, default=2, help='depth of the GNN')\n",
    "parser.add_argument('--max_lr', type=float, default=0.001, help='maximum learning rate')\n",
    "parser.add_argument('--warmup', type=float, default=0.1, help='warmup ratio for learning rate')\n",
    "parser.add_argument('--max_epoch', type=int, default=200, help='maximum number of epochs')\n",
    "parser.add_argument('--early_stop', type=int, default=40, help='early stopping epochs')\n",
    "parser.add_argument('--device', type=int, default=0, help='GPU ID')\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "pprint(args)\n",
    "\n",
    "args.device = torch.device(f'cuda:{args.device}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(args.random_seed)\n",
    "torch.cuda.manual_seed(args.random_seed)\n",
    "dgl.seed(args.random_seed)\n",
    "np.random.seed(args.random_seed)\n",
    "random.seed(args.random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39297350-c825-4a1d-9944-39c489028c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing graph...\n",
      "\u001b[FConstructing graph... Done\n",
      "Splitting graph...\n",
      "\u001b[FSplitting graph... Done\n",
      "---------------------Data statistics---------------------\n",
      "#[Train] nodes: [1489, 1489, 1489, 1489], edges: [28076, 24164, 29070, 23326], target edges: [28076, 24164, 29070, 23326]\n",
      "#[Valid] nodes: 1985, edges: 53672, target edges: 53672\n",
      "#[Test]  nodes: 1986, edges: 49372, target edges: 49372\n",
      "---------------------------------------------------------\n",
      "\n",
      "2024-08-21 01:32:00 start\n",
      "2024-08-21 01:32:07 Epoch [1/200], Train Loss: 0.7013, Valid Loss: 0.6927, Precision: 0.5734, Recall: 0.0076, F1: 0.0150\n",
      "2024-08-21 01:32:10 Epoch [2/200], Train Loss: 0.6934, Valid Loss: 0.6934, Precision: 0.5060, Recall: 0.9952, F1: 0.6709\n",
      "2024-08-21 01:32:14 Epoch [3/200], Train Loss: 0.6842, Valid Loss: 0.6980, Precision: 0.5070, Recall: 1.0000, F1: 0.6728\n",
      "2024-08-21 01:32:18 Epoch [4/200], Train Loss: 0.6774, Valid Loss: 0.7114, Precision: 0.5070, Recall: 1.0000, F1: 0.6728\n",
      "2024-08-21 01:32:21 Epoch [5/200], Train Loss: 0.6742, Valid Loss: 0.7249, Precision: 0.5070, Recall: 1.0000, F1: 0.6728\n",
      "2024-08-21 01:32:25 Epoch [6/200], Train Loss: 0.6706, Valid Loss: 0.7117, Precision: 0.5070, Recall: 1.0000, F1: 0.6728\n",
      "2024-08-21 01:32:29 Epoch [7/200], Train Loss: 0.6607, Valid Loss: 0.6928, Precision: 0.5070, Recall: 1.0000, F1: 0.6728\n",
      "2024-08-21 01:32:33 Epoch [8/200], Train Loss: 0.6508, Valid Loss: 0.6742, Precision: 0.5070, Recall: 1.0000, F1: 0.6728\n",
      "2024-08-21 01:32:36 Epoch [9/200], Train Loss: 0.6376, Valid Loss: 0.6536, Precision: 0.6245, Recall: 0.9681, F1: 0.7592\n",
      "2024-08-21 01:32:40 Epoch [10/200], Train Loss: 0.6157, Valid Loss: 0.6269, Precision: 0.6751, Recall: 0.8630, F1: 0.7575\n",
      "2024-08-21 01:32:44 Epoch [11/200], Train Loss: 0.6070, Valid Loss: 0.5945, Precision: 0.6731, Recall: 0.8367, F1: 0.7460\n",
      "2024-08-21 01:32:47 Epoch [12/200], Train Loss: 0.6112, Valid Loss: 0.6054, Precision: 0.6836, Recall: 0.7611, F1: 0.7203\n",
      "2024-08-21 01:32:51 Epoch [13/200], Train Loss: 0.5650, Valid Loss: 0.5622, Precision: 0.7011, Recall: 0.7917, F1: 0.7436\n",
      "2024-08-21 01:32:54 Epoch [14/200], Train Loss: 0.5431, Valid Loss: 0.5234, Precision: 0.6980, Recall: 0.8607, F1: 0.7709\n",
      "2024-08-21 01:32:58 Epoch [15/200], Train Loss: 0.5141, Valid Loss: 0.5194, Precision: 0.7337, Recall: 0.7676, F1: 0.7503\n",
      "2024-08-21 01:33:01 Epoch [16/200], Train Loss: 0.4849, Valid Loss: 0.5615, Precision: 0.7614, Recall: 0.5427, F1: 0.6337\n",
      "2024-08-21 01:33:05 Epoch [17/200], Train Loss: 0.4883, Valid Loss: 0.5494, Precision: 0.7710, Recall: 0.5617, F1: 0.6499\n",
      "2024-08-21 01:33:08 Epoch [18/200], Train Loss: 0.4521, Valid Loss: 0.4884, Precision: 0.7477, Recall: 0.7745, F1: 0.7608\n",
      "2024-08-21 01:33:12 Epoch [19/200], Train Loss: 0.4355, Valid Loss: 0.4820, Precision: 0.7601, Recall: 0.7582, F1: 0.7591\n",
      "2024-08-21 01:33:16 Epoch [20/200], Train Loss: 0.4367, Valid Loss: 0.5411, Precision: 0.8009, Recall: 0.5652, F1: 0.6627\n",
      "2024-08-21 01:33:19 Epoch [21/200], Train Loss: 0.4329, Valid Loss: 0.4507, Precision: 0.7504, Recall: 0.8732, F1: 0.8071\n",
      "2024-08-21 01:33:23 Epoch [22/200], Train Loss: 0.4126, Valid Loss: 0.4553, Precision: 0.7760, Recall: 0.8083, F1: 0.7918\n",
      "2024-08-21 01:33:26 Epoch [23/200], Train Loss: 0.4129, Valid Loss: 0.5077, Precision: 0.8052, Recall: 0.6497, F1: 0.7191\n",
      "2024-08-21 01:33:30 Epoch [24/200], Train Loss: 0.4097, Valid Loss: 0.4535, Precision: 0.7854, Recall: 0.8155, F1: 0.8002\n",
      "2024-08-21 01:33:33 Epoch [25/200], Train Loss: 0.3993, Valid Loss: 0.4528, Precision: 0.7894, Recall: 0.8105, F1: 0.7998\n",
      "2024-08-21 01:33:37 Epoch [26/200], Train Loss: 0.3961, Valid Loss: 0.4652, Precision: 0.8004, Recall: 0.7702, F1: 0.7850\n",
      "2024-08-21 01:33:40 Epoch [27/200], Train Loss: 0.3951, Valid Loss: 0.4523, Precision: 0.7947, Recall: 0.8002, F1: 0.7974\n",
      "2024-08-21 01:33:43 Epoch [28/200], Train Loss: 0.3929, Valid Loss: 0.4652, Precision: 0.8047, Recall: 0.7563, F1: 0.7797\n",
      "2024-08-21 01:33:47 Epoch [29/200], Train Loss: 0.3849, Valid Loss: 0.4626, Precision: 0.8050, Recall: 0.7595, F1: 0.7816\n",
      "2024-08-21 01:33:50 Epoch [30/200], Train Loss: 0.3849, Valid Loss: 0.4713, Precision: 0.8145, Recall: 0.7254, F1: 0.7674\n",
      "2024-08-21 01:33:54 Epoch [31/200], Train Loss: 0.3788, Valid Loss: 0.4450, Precision: 0.8002, Recall: 0.8114, F1: 0.8058\n",
      "2024-08-21 01:33:58 Epoch [32/200], Train Loss: 0.3788, Valid Loss: 0.4753, Precision: 0.8202, Recall: 0.7052, F1: 0.7584\n",
      "2024-08-21 01:34:01 Epoch [33/200], Train Loss: 0.3761, Valid Loss: 0.4806, Precision: 0.8216, Recall: 0.6830, F1: 0.7459\n",
      "2024-08-21 01:34:05 Epoch [34/200], Train Loss: 0.3736, Valid Loss: 0.4820, Precision: 0.8266, Recall: 0.6829, F1: 0.7479\n",
      "2024-08-21 01:34:08 Epoch [35/200], Train Loss: 0.3691, Valid Loss: 0.4552, Precision: 0.8145, Recall: 0.7701, F1: 0.7917\n",
      "2024-08-21 01:34:12 Epoch [36/200], Train Loss: 0.3701, Valid Loss: 0.4709, Precision: 0.8246, Recall: 0.7198, F1: 0.7687\n",
      "2024-08-21 01:34:15 Epoch [37/200], Train Loss: 0.3690, Valid Loss: 0.4705, Precision: 0.8239, Recall: 0.7162, F1: 0.7663\n",
      "2024-08-21 01:34:19 Epoch [38/200], Train Loss: 0.3699, Valid Loss: 0.5126, Precision: 0.8422, Recall: 0.5833, F1: 0.6893\n",
      "2024-08-21 01:34:22 Epoch [39/200], Train Loss: 0.3709, Valid Loss: 0.5238, Precision: 0.8458, Recall: 0.5596, F1: 0.6736\n",
      "2024-08-21 01:34:26 Epoch [40/200], Train Loss: 0.3708, Valid Loss: 0.4223, Precision: 0.7949, Recall: 0.8631, F1: 0.8276\n",
      "2024-08-21 01:34:30 Epoch [41/200], Train Loss: 0.3744, Valid Loss: 0.4594, Precision: 0.8231, Recall: 0.7415, F1: 0.7802\n",
      "2024-08-21 01:34:33 Epoch [42/200], Train Loss: 0.3713, Valid Loss: 0.5102, Precision: 0.8412, Recall: 0.5914, F1: 0.6945\n",
      "2024-08-21 01:34:36 Epoch [43/200], Train Loss: 0.3666, Valid Loss: 0.4520, Precision: 0.8186, Recall: 0.7641, F1: 0.7904\n",
      "2024-08-21 01:34:40 Epoch [44/200], Train Loss: 0.3700, Valid Loss: 0.4154, Precision: 0.7925, Recall: 0.8800, F1: 0.8340\n",
      "2024-08-21 01:34:44 Epoch [45/200], Train Loss: 0.3730, Valid Loss: 0.4469, Precision: 0.8168, Recall: 0.7923, F1: 0.8044\n",
      "2024-08-21 01:34:47 Epoch [46/200], Train Loss: 0.3656, Valid Loss: 0.4444, Precision: 0.8124, Recall: 0.7983, F1: 0.8053\n",
      "2024-08-21 01:34:51 Epoch [47/200], Train Loss: 0.3646, Valid Loss: 0.4502, Precision: 0.8152, Recall: 0.7802, F1: 0.7973\n",
      "2024-08-21 01:34:55 Epoch [48/200], Train Loss: 0.3656, Valid Loss: 0.4353, Precision: 0.8080, Recall: 0.8221, F1: 0.8150\n",
      "2024-08-21 01:34:58 Epoch [49/200], Train Loss: 0.3593, Valid Loss: 0.4460, Precision: 0.8161, Recall: 0.7881, F1: 0.8018\n",
      "2024-08-21 01:35:02 Epoch [50/200], Train Loss: 0.3599, Valid Loss: 0.4451, Precision: 0.8166, Recall: 0.7929, F1: 0.8046\n",
      "2024-08-21 01:35:05 Epoch [51/200], Train Loss: 0.3548, Valid Loss: 0.4434, Precision: 0.8178, Recall: 0.7875, F1: 0.8024\n",
      "2024-08-21 01:35:09 Epoch [52/200], Train Loss: 0.3502, Valid Loss: 0.4547, Precision: 0.8236, Recall: 0.7493, F1: 0.7847\n",
      "2024-08-21 01:35:12 Epoch [53/200], Train Loss: 0.3522, Valid Loss: 0.4641, Precision: 0.8266, Recall: 0.7278, F1: 0.7741\n",
      "2024-08-21 01:35:16 Epoch [54/200], Train Loss: 0.3563, Valid Loss: 0.4463, Precision: 0.8170, Recall: 0.7850, F1: 0.8007\n",
      "2024-08-21 01:35:19 Epoch [55/200], Train Loss: 0.3502, Valid Loss: 0.4713, Precision: 0.8281, Recall: 0.7153, F1: 0.7676\n",
      "2024-08-21 01:35:23 Epoch [56/200], Train Loss: 0.3482, Valid Loss: 0.4350, Precision: 0.8130, Recall: 0.8068, F1: 0.8099\n",
      "2024-08-21 01:35:26 Epoch [57/200], Train Loss: 0.3479, Valid Loss: 0.4512, Precision: 0.8195, Recall: 0.7629, F1: 0.7902\n",
      "2024-08-21 01:35:29 Epoch [58/200], Train Loss: 0.3479, Valid Loss: 0.4989, Precision: 0.8351, Recall: 0.6425, F1: 0.7262\n",
      "2024-08-21 01:35:33 Epoch [59/200], Train Loss: 0.3502, Valid Loss: 0.4564, Precision: 0.8198, Recall: 0.7584, F1: 0.7879\n",
      "2024-08-21 01:35:37 Epoch [60/200], Train Loss: 0.3471, Valid Loss: 0.4385, Precision: 0.8123, Recall: 0.8022, F1: 0.8072\n",
      "2024-08-21 01:35:40 Epoch [61/200], Train Loss: 0.3471, Valid Loss: 0.4779, Precision: 0.8285, Recall: 0.7049, F1: 0.7617\n",
      "2024-08-21 01:35:44 Epoch [62/200], Train Loss: 0.3420, Valid Loss: 0.4992, Precision: 0.8362, Recall: 0.6501, F1: 0.7315\n",
      "2024-08-21 01:35:47 Epoch [63/200], Train Loss: 0.3428, Valid Loss: 0.4575, Precision: 0.8189, Recall: 0.7508, F1: 0.7834\n",
      "2024-08-21 01:35:51 Epoch [64/200], Train Loss: 0.3413, Valid Loss: 0.4634, Precision: 0.8212, Recall: 0.7352, F1: 0.7758\n",
      "2024-08-21 01:35:54 Epoch [65/200], Train Loss: 0.3406, Valid Loss: 0.4985, Precision: 0.8356, Recall: 0.6286, F1: 0.7175\n",
      "2024-08-21 01:35:57 Epoch [66/200], Train Loss: 0.3452, Valid Loss: 0.4740, Precision: 0.8248, Recall: 0.7122, F1: 0.7644\n",
      "2024-08-21 01:36:01 Epoch [67/200], Train Loss: 0.3415, Valid Loss: 0.4576, Precision: 0.8200, Recall: 0.7519, F1: 0.7845\n",
      "2024-08-21 01:36:05 Epoch [68/200], Train Loss: 0.3457, Valid Loss: 0.4462, Precision: 0.8179, Recall: 0.7749, F1: 0.7958\n",
      "2024-08-21 01:36:08 Epoch [69/200], Train Loss: 0.3470, Valid Loss: 0.4771, Precision: 0.8303, Recall: 0.6988, F1: 0.7589\n",
      "2024-08-21 01:36:12 Epoch [70/200], Train Loss: 0.3412, Valid Loss: 0.4436, Precision: 0.8117, Recall: 0.7813, F1: 0.7962\n",
      "2024-08-21 01:36:15 Epoch [71/200], Train Loss: 0.3444, Valid Loss: 0.4459, Precision: 0.8141, Recall: 0.7738, F1: 0.7934\n",
      "2024-08-21 01:36:19 Epoch [72/200], Train Loss: 0.3423, Valid Loss: 0.4885, Precision: 0.8309, Recall: 0.6695, F1: 0.7415\n",
      "2024-08-21 01:36:22 Epoch [73/200], Train Loss: 0.3351, Valid Loss: 0.4710, Precision: 0.8223, Recall: 0.7196, F1: 0.7675\n",
      "2024-08-21 01:36:26 Epoch [74/200], Train Loss: 0.3378, Valid Loss: 0.5055, Precision: 0.8319, Recall: 0.6200, F1: 0.7105\n",
      "2024-08-21 01:36:29 Epoch [75/200], Train Loss: 0.3295, Valid Loss: 0.4730, Precision: 0.8262, Recall: 0.7065, F1: 0.7617\n",
      "2024-08-21 01:36:33 Epoch [76/200], Train Loss: 0.3278, Valid Loss: 0.4675, Precision: 0.8235, Recall: 0.7244, F1: 0.7708\n",
      "2024-08-21 01:36:37 Epoch [77/200], Train Loss: 0.3372, Valid Loss: 0.5140, Precision: 0.8367, Recall: 0.5945, F1: 0.6951\n",
      "2024-08-21 01:36:40 Epoch [78/200], Train Loss: 0.3264, Valid Loss: 0.4563, Precision: 0.8164, Recall: 0.7605, F1: 0.7875\n",
      "2024-08-21 01:36:44 Epoch [79/200], Train Loss: 0.3251, Valid Loss: 0.4966, Precision: 0.8349, Recall: 0.6456, F1: 0.7282\n",
      "2024-08-21 01:36:48 Epoch [80/200], Train Loss: 0.3225, Valid Loss: 0.4906, Precision: 0.8335, Recall: 0.6506, F1: 0.7308\n",
      "2024-08-21 01:36:51 Epoch [81/200], Train Loss: 0.3206, Valid Loss: 0.4598, Precision: 0.8243, Recall: 0.7349, F1: 0.7770\n",
      "2024-08-21 01:36:55 Epoch [82/200], Train Loss: 0.3269, Valid Loss: 0.5064, Precision: 0.8421, Recall: 0.5762, F1: 0.6842\n",
      "2024-08-21 01:36:58 Epoch [83/200], Train Loss: 0.3294, Valid Loss: 0.4711, Precision: 0.8246, Recall: 0.7069, F1: 0.7613\n",
      "2024-08-21 01:37:02 Epoch [84/200], Train Loss: 0.3292, Valid Loss: 0.4567, Precision: 0.8178, Recall: 0.7651, F1: 0.7906\n",
      "2024-08-21 01:37:06 Epoch [85/200], Train Loss: 0.3296, Valid Loss: 0.4724, Precision: 0.8248, Recall: 0.7141, F1: 0.7655\n",
      "2024-08-21 01:37:09 Epoch [86/200], Train Loss: 0.3294, Valid Loss: 0.4815, Precision: 0.8272, Recall: 0.6843, F1: 0.7490\n",
      "2024-08-21 01:37:13 Epoch [87/200], Train Loss: 0.3272, Valid Loss: 0.4611, Precision: 0.8191, Recall: 0.7380, F1: 0.7764\n",
      "2024-08-21 01:37:16 Epoch [88/200], Train Loss: 0.3283, Valid Loss: 0.4858, Precision: 0.8282, Recall: 0.6732, F1: 0.7427\n",
      "2024-08-21 01:37:20 Epoch [89/200], Train Loss: 0.3246, Valid Loss: 0.4635, Precision: 0.8201, Recall: 0.7460, F1: 0.7813\n",
      "2024-08-21 01:37:24 Epoch [90/200], Train Loss: 0.3210, Valid Loss: 0.4878, Precision: 0.8311, Recall: 0.6564, F1: 0.7335\n",
      "2024-08-21 01:37:27 Epoch [91/200], Train Loss: 0.3171, Valid Loss: 0.4869, Precision: 0.8295, Recall: 0.6484, F1: 0.7279\n",
      "2024-08-21 01:37:31 Epoch [92/200], Train Loss: 0.3207, Valid Loss: 0.4569, Precision: 0.8165, Recall: 0.7688, F1: 0.7919\n",
      "2024-08-21 01:37:34 Epoch [93/200], Train Loss: 0.3177, Valid Loss: 0.4909, Precision: 0.8279, Recall: 0.6589, F1: 0.7338\n",
      "2024-08-21 01:37:38 Epoch [94/200], Train Loss: 0.3162, Valid Loss: 0.4777, Precision: 0.8192, Recall: 0.7197, F1: 0.7663\n",
      "2024-08-21 01:37:42 Epoch [95/200], Train Loss: 0.3175, Valid Loss: 0.5377, Precision: 0.8368, Recall: 0.4373, F1: 0.5744\n",
      "2024-08-21 01:37:45 Epoch [96/200], Train Loss: 0.3189, Valid Loss: 0.4916, Precision: 0.8282, Recall: 0.6373, F1: 0.7203\n",
      "2024-08-21 01:37:49 Epoch [97/200], Train Loss: 0.3167, Valid Loss: 0.4895, Precision: 0.8293, Recall: 0.6419, F1: 0.7237\n",
      "2024-08-21 01:37:52 Epoch [98/200], Train Loss: 0.3136, Valid Loss: 0.5154, Precision: 0.8385, Recall: 0.5515, F1: 0.6654\n",
      "2024-08-21 01:37:56 Epoch [99/200], Train Loss: 0.3135, Valid Loss: 0.4595, Precision: 0.8146, Recall: 0.7584, F1: 0.7855\n",
      "2024-08-21 01:38:00 Epoch [100/200], Train Loss: 0.3158, Valid Loss: 0.4628, Precision: 0.8155, Recall: 0.7612, F1: 0.7874\n",
      "2024-08-21 01:38:03 Epoch [101/200], Train Loss: 0.3117, Valid Loss: 0.4544, Precision: 0.8024, Recall: 0.8441, F1: 0.8227\n",
      "2024-08-21 01:38:07 Epoch [102/200], Train Loss: 0.3121, Valid Loss: 0.4524, Precision: 0.7951, Recall: 0.8645, F1: 0.8284\n",
      "2024-08-21 01:38:10 Epoch [103/200], Train Loss: 0.3130, Valid Loss: 0.4951, Precision: 0.8101, Recall: 0.7703, F1: 0.7897\n",
      "2024-08-21 01:38:14 Epoch [104/200], Train Loss: 0.3129, Valid Loss: 0.4950, Precision: 0.7875, Recall: 0.8567, F1: 0.8207\n",
      "2024-08-21 01:38:18 Epoch [105/200], Train Loss: 0.3121, Valid Loss: 0.4791, Precision: 0.7940, Recall: 0.7891, F1: 0.7915\n",
      "2024-08-21 01:38:21 Epoch [106/200], Train Loss: 0.3097, Valid Loss: 0.5146, Precision: 0.7954, Recall: 0.7404, F1: 0.7669\n",
      "2024-08-21 01:38:25 Epoch [107/200], Train Loss: 0.3109, Valid Loss: 0.5487, Precision: 0.7875, Recall: 0.6910, F1: 0.7361\n",
      "2024-08-21 01:38:28 Epoch [108/200], Train Loss: 0.3075, Valid Loss: 0.5890, Precision: 0.7729, Recall: 0.4061, F1: 0.5325\n",
      "2024-08-21 01:38:32 Epoch [109/200], Train Loss: 0.3069, Valid Loss: 0.5186, Precision: 0.7965, Recall: 0.6991, F1: 0.7446\n",
      "2024-08-21 01:38:36 Epoch [110/200], Train Loss: 0.3056, Valid Loss: 0.5329, Precision: 0.8134, Recall: 0.6162, F1: 0.7012\n",
      "2024-08-21 01:38:39 Epoch [111/200], Train Loss: 0.3060, Valid Loss: 0.5259, Precision: 0.8025, Recall: 0.7379, F1: 0.7689\n",
      "2024-08-21 01:38:43 Epoch [112/200], Train Loss: 0.3029, Valid Loss: 0.5233, Precision: 0.8049, Recall: 0.6861, F1: 0.7408\n",
      "2024-08-21 01:38:47 Epoch [113/200], Train Loss: 0.3039, Valid Loss: 0.5368, Precision: 0.8127, Recall: 0.5344, F1: 0.6448\n",
      "2024-08-21 01:38:50 Epoch [114/200], Train Loss: 0.3015, Valid Loss: 0.5347, Precision: 0.7915, Recall: 0.6922, F1: 0.7385\n",
      "2024-08-21 01:38:53 Epoch [115/200], Train Loss: 0.3002, Valid Loss: 0.5620, Precision: 0.7834, Recall: 0.5313, F1: 0.6331\n",
      "2024-08-21 01:38:57 Epoch [116/200], Train Loss: 0.3022, Valid Loss: 0.5581, Precision: 0.7747, Recall: 0.7264, F1: 0.7498\n",
      "2024-08-21 01:39:00 Epoch [117/200], Train Loss: 0.2997, Valid Loss: 0.5835, Precision: 0.7560, Recall: 0.6515, F1: 0.6999\n",
      "2024-08-21 01:39:04 Epoch [118/200], Train Loss: 0.3013, Valid Loss: 0.5842, Precision: 0.7687, Recall: 0.6498, F1: 0.7043\n",
      "2024-08-21 01:39:07 Epoch [119/200], Train Loss: 0.3026, Valid Loss: 0.5626, Precision: 0.7834, Recall: 0.7012, F1: 0.7400\n",
      "2024-08-21 01:39:11 Epoch [120/200], Train Loss: 0.2992, Valid Loss: 0.5751, Precision: 0.7665, Recall: 0.6890, F1: 0.7257\n",
      "2024-08-21 01:39:14 Epoch [121/200], Train Loss: 0.2975, Valid Loss: 0.6014, Precision: 0.7112, Recall: 0.4901, F1: 0.5803\n",
      "2024-08-21 01:39:18 Epoch [122/200], Train Loss: 0.2974, Valid Loss: 0.6029, Precision: 0.7082, Recall: 0.4746, F1: 0.5683\n",
      "2024-08-21 01:39:21 Epoch [123/200], Train Loss: 0.2955, Valid Loss: 0.5848, Precision: 0.7591, Recall: 0.5833, F1: 0.6597\n",
      "2024-08-21 01:39:25 Epoch [124/200], Train Loss: 0.2970, Valid Loss: 0.5807, Precision: 0.7741, Recall: 0.6360, F1: 0.6983\n",
      "2024-08-21 01:39:28 Epoch [125/200], Train Loss: 0.2964, Valid Loss: 0.5862, Precision: 0.7666, Recall: 0.5252, F1: 0.6234\n",
      "2024-08-21 01:39:32 Epoch [126/200], Train Loss: 0.2949, Valid Loss: 0.5878, Precision: 0.7620, Recall: 0.4492, F1: 0.5652\n",
      "2024-08-21 01:39:36 Epoch [127/200], Train Loss: 0.2937, Valid Loss: 0.5604, Precision: 0.7807, Recall: 0.6440, F1: 0.7058\n",
      "2024-08-21 01:39:39 Epoch [128/200], Train Loss: 0.2992, Valid Loss: 0.5504, Precision: 0.7831, Recall: 0.7328, F1: 0.7571\n",
      "2024-08-21 01:39:43 Epoch [129/200], Train Loss: 0.2935, Valid Loss: 0.5507, Precision: 0.7744, Recall: 0.7259, F1: 0.7494\n",
      "2024-08-21 01:39:46 Epoch [130/200], Train Loss: 0.3012, Valid Loss: 0.5690, Precision: 0.7643, Recall: 0.5973, F1: 0.6706\n",
      "2024-08-21 01:39:49 Epoch [131/200], Train Loss: 0.2925, Valid Loss: 0.5833, Precision: 0.7254, Recall: 0.5490, F1: 0.6250\n",
      "2024-08-21 01:39:53 Epoch [132/200], Train Loss: 0.2940, Valid Loss: 0.5786, Precision: 0.7398, Recall: 0.6747, F1: 0.7058\n",
      "2024-08-21 01:39:56 Epoch [133/200], Train Loss: 0.2930, Valid Loss: 0.5796, Precision: 0.7330, Recall: 0.5896, F1: 0.6535\n",
      "2024-08-21 01:40:00 Epoch [134/200], Train Loss: 0.2895, Valid Loss: 0.5752, Precision: 0.7667, Recall: 0.5201, F1: 0.6197\n",
      "2024-08-21 01:40:04 Epoch [135/200], Train Loss: 0.2954, Valid Loss: 0.5800, Precision: 0.7467, Recall: 0.5058, F1: 0.6031\n",
      "2024-08-21 01:40:07 Epoch [136/200], Train Loss: 0.2938, Valid Loss: 0.5795, Precision: 0.7308, Recall: 0.5802, F1: 0.6469\n",
      "2024-08-21 01:40:11 Epoch [137/200], Train Loss: 0.2924, Valid Loss: 0.5788, Precision: 0.7401, Recall: 0.6587, F1: 0.6970\n",
      "2024-08-21 01:40:15 Epoch [138/200], Train Loss: 0.2912, Valid Loss: 0.5729, Precision: 0.7436, Recall: 0.7248, F1: 0.7341\n",
      "2024-08-21 01:40:18 Epoch [139/200], Train Loss: 0.2881, Valid Loss: 0.5735, Precision: 0.7409, Recall: 0.6766, F1: 0.7072\n",
      "2024-08-21 01:40:22 Epoch [140/200], Train Loss: 0.2896, Valid Loss: 0.5798, Precision: 0.7275, Recall: 0.5515, F1: 0.6274\n",
      "2024-08-21 01:40:25 Epoch [141/200], Train Loss: 0.2928, Valid Loss: 0.5938, Precision: 0.7017, Recall: 0.4321, F1: 0.5349\n",
      "2024-08-21 01:40:29 Epoch [142/200], Train Loss: 0.2906, Valid Loss: 0.6049, Precision: 0.6789, Recall: 0.3585, F1: 0.4692\n",
      "2024-08-21 01:40:32 Epoch [143/200], Train Loss: 0.2896, Valid Loss: 0.5993, Precision: 0.6947, Recall: 0.4058, F1: 0.5123\n",
      "2024-08-21 01:40:36 Epoch [144/200], Train Loss: 0.2899, Valid Loss: 0.5724, Precision: 0.7418, Recall: 0.6696, F1: 0.7039\n",
      "2024-08-21 01:40:39 Epoch [145/200], Train Loss: 0.2892, Valid Loss: 0.5615, Precision: 0.7465, Recall: 0.7827, F1: 0.7642\n",
      "2024-08-21 01:40:43 Epoch [146/200], Train Loss: 0.2884, Valid Loss: 0.5617, Precision: 0.7470, Recall: 0.7861, F1: 0.7660\n",
      "2024-08-21 01:40:46 Epoch [147/200], Train Loss: 0.2904, Valid Loss: 0.5685, Precision: 0.7461, Recall: 0.7859, F1: 0.7655\n",
      "2024-08-21 01:40:50 Epoch [148/200], Train Loss: 0.2938, Valid Loss: 0.5686, Precision: 0.7475, Recall: 0.8157, F1: 0.7801\n",
      "2024-08-21 01:40:54 Epoch [149/200], Train Loss: 0.2878, Valid Loss: 0.5661, Precision: 0.7634, Recall: 0.7644, F1: 0.7639\n",
      "2024-08-21 01:40:57 Epoch [150/200], Train Loss: 0.2856, Valid Loss: 0.5620, Precision: 0.7809, Recall: 0.7178, F1: 0.7480\n",
      "2024-08-21 01:41:01 Epoch [151/200], Train Loss: 0.2869, Valid Loss: 0.5623, Precision: 0.7835, Recall: 0.6800, F1: 0.7281\n",
      "2024-08-21 01:41:05 Epoch [152/200], Train Loss: 0.2881, Valid Loss: 0.5712, Precision: 0.7834, Recall: 0.5869, F1: 0.6711\n",
      "2024-08-21 01:41:08 Epoch [153/200], Train Loss: 0.2919, Valid Loss: 0.5859, Precision: 0.7732, Recall: 0.4567, F1: 0.5742\n",
      "2024-08-21 01:41:12 Epoch [154/200], Train Loss: 0.2876, Valid Loss: 0.5902, Precision: 0.7597, Recall: 0.4531, F1: 0.5676\n",
      "2024-08-21 01:41:15 Epoch [155/200], Train Loss: 0.2842, Valid Loss: 0.5871, Precision: 0.7328, Recall: 0.5516, F1: 0.6294\n",
      "2024-08-21 01:41:19 Epoch [156/200], Train Loss: 0.2895, Valid Loss: 0.5823, Precision: 0.7380, Recall: 0.6352, F1: 0.6828\n",
      "2024-08-21 01:41:22 Epoch [157/200], Train Loss: 0.2868, Valid Loss: 0.5807, Precision: 0.7408, Recall: 0.6903, F1: 0.7147\n",
      "2024-08-21 01:41:26 Epoch [158/200], Train Loss: 0.2884, Valid Loss: 0.5796, Precision: 0.7412, Recall: 0.7040, F1: 0.7221\n",
      "2024-08-21 01:41:29 Epoch [159/200], Train Loss: 0.2876, Valid Loss: 0.5791, Precision: 0.7397, Recall: 0.6878, F1: 0.7128\n",
      "2024-08-21 01:41:33 Epoch [160/200], Train Loss: 0.2857, Valid Loss: 0.5778, Precision: 0.7361, Recall: 0.6445, F1: 0.6873\n",
      "2024-08-21 01:41:36 Epoch [161/200], Train Loss: 0.2868, Valid Loss: 0.5781, Precision: 0.7316, Recall: 0.5964, F1: 0.6571\n",
      "2024-08-21 01:41:40 Epoch [162/200], Train Loss: 0.2873, Valid Loss: 0.5784, Precision: 0.7276, Recall: 0.5655, F1: 0.6364\n",
      "2024-08-21 01:41:43 Epoch [163/200], Train Loss: 0.2880, Valid Loss: 0.5793, Precision: 0.7229, Recall: 0.5380, F1: 0.6169\n",
      "2024-08-21 01:41:46 Epoch [164/200], Train Loss: 0.2875, Valid Loss: 0.5809, Precision: 0.7245, Recall: 0.5433, F1: 0.6209\n",
      "2024-08-21 01:41:50 Epoch [165/200], Train Loss: 0.2874, Valid Loss: 0.5839, Precision: 0.7268, Recall: 0.5544, F1: 0.6290\n",
      "2024-08-21 01:41:54 Epoch [166/200], Train Loss: 0.2896, Valid Loss: 0.5882, Precision: 0.7252, Recall: 0.5426, F1: 0.6208\n",
      "2024-08-21 01:41:57 Epoch [167/200], Train Loss: 0.2863, Valid Loss: 0.5915, Precision: 0.7212, Recall: 0.5214, F1: 0.6052\n",
      "2024-08-21 01:42:00 Epoch [168/200], Train Loss: 0.2870, Valid Loss: 0.5906, Precision: 0.7244, Recall: 0.5362, F1: 0.6162\n",
      "2024-08-21 01:42:04 Epoch [169/200], Train Loss: 0.2859, Valid Loss: 0.5869, Precision: 0.7329, Recall: 0.5847, F1: 0.6504\n",
      "2024-08-21 01:42:07 Epoch [170/200], Train Loss: 0.2818, Valid Loss: 0.5835, Precision: 0.7386, Recall: 0.6279, F1: 0.6788\n",
      "2024-08-21 01:42:11 Epoch [171/200], Train Loss: 0.2857, Valid Loss: 0.5807, Precision: 0.7403, Recall: 0.6455, F1: 0.6896\n",
      "2024-08-21 01:42:14 Epoch [172/200], Train Loss: 0.2858, Valid Loss: 0.5780, Precision: 0.7390, Recall: 0.6315, F1: 0.6810\n",
      "2024-08-21 01:42:18 Epoch [173/200], Train Loss: 0.2822, Valid Loss: 0.5765, Precision: 0.7419, Recall: 0.6195, F1: 0.6752\n",
      "2024-08-21 01:42:21 Epoch [174/200], Train Loss: 0.2834, Valid Loss: 0.5770, Precision: 0.7406, Recall: 0.6059, F1: 0.6665\n",
      "2024-08-21 01:42:25 Epoch [175/200], Train Loss: 0.2866, Valid Loss: 0.5785, Precision: 0.7359, Recall: 0.5992, F1: 0.6605\n",
      "2024-08-21 01:42:29 Epoch [176/200], Train Loss: 0.2880, Valid Loss: 0.5788, Precision: 0.7361, Recall: 0.6087, F1: 0.6664\n",
      "2024-08-21 01:42:32 Epoch [177/200], Train Loss: 0.2849, Valid Loss: 0.5800, Precision: 0.7371, Recall: 0.6161, F1: 0.6712\n",
      "2024-08-21 01:42:36 Epoch [178/200], Train Loss: 0.2845, Valid Loss: 0.5804, Precision: 0.7372, Recall: 0.6206, F1: 0.6739\n",
      "2024-08-21 01:42:39 Epoch [179/200], Train Loss: 0.2884, Valid Loss: 0.5817, Precision: 0.7375, Recall: 0.6200, F1: 0.6737\n",
      "2024-08-21 01:42:43 Epoch [180/200], Train Loss: 0.2896, Valid Loss: 0.5837, Precision: 0.7360, Recall: 0.6114, F1: 0.6679\n",
      "2024-08-21 01:42:47 Epoch [181/200], Train Loss: 0.2825, Valid Loss: 0.5855, Precision: 0.7359, Recall: 0.6069, F1: 0.6652\n",
      "2024-08-21 01:42:50 Epoch [182/200], Train Loss: 0.2839, Valid Loss: 0.5851, Precision: 0.7352, Recall: 0.6079, F1: 0.6655\n",
      "2024-08-21 01:42:54 Epoch [183/200], Train Loss: 0.2861, Valid Loss: 0.5861, Precision: 0.7354, Recall: 0.6090, F1: 0.6663\n",
      "2024-08-21 01:42:57 Epoch [184/200], Train Loss: 0.2872, Valid Loss: 0.5863, Precision: 0.7368, Recall: 0.6115, F1: 0.6683\n",
      "2024-08-21 01:43:01 Epoch [185/200], Train Loss: 0.2849, Valid Loss: 0.5859, Precision: 0.7375, Recall: 0.6171, F1: 0.6720\n",
      "2024-08-21 01:43:05 Epoch [186/200], Train Loss: 0.2871, Valid Loss: 0.5860, Precision: 0.7376, Recall: 0.6168, F1: 0.6718\n",
      "2024-08-21 01:43:08 Epoch [187/200], Train Loss: 0.2842, Valid Loss: 0.5861, Precision: 0.7374, Recall: 0.6163, F1: 0.6714\n",
      "2024-08-21 01:43:12 Epoch [188/200], Train Loss: 0.2860, Valid Loss: 0.5850, Precision: 0.7377, Recall: 0.6197, F1: 0.6736\n",
      "2024-08-21 01:43:15 Epoch [189/200], Train Loss: 0.2842, Valid Loss: 0.5846, Precision: 0.7387, Recall: 0.6231, F1: 0.6760\n",
      "2024-08-21 01:43:19 Epoch [190/200], Train Loss: 0.2851, Valid Loss: 0.5850, Precision: 0.7387, Recall: 0.6249, F1: 0.6771\n",
      "2024-08-21 01:43:22 Epoch [191/200], Train Loss: 0.2856, Valid Loss: 0.5844, Precision: 0.7388, Recall: 0.6275, F1: 0.6786\n",
      "2024-08-21 01:43:26 Epoch [192/200], Train Loss: 0.2831, Valid Loss: 0.5847, Precision: 0.7395, Recall: 0.6293, F1: 0.6800\n",
      "2024-08-21 01:43:29 Epoch [193/200], Train Loss: 0.2863, Valid Loss: 0.5845, Precision: 0.7387, Recall: 0.6315, F1: 0.6809\n",
      "2024-08-21 01:43:33 Epoch [194/200], Train Loss: 0.2836, Valid Loss: 0.5840, Precision: 0.7396, Recall: 0.6326, F1: 0.6819\n",
      "2024-08-21 01:43:36 Epoch [195/200], Train Loss: 0.2860, Valid Loss: 0.5837, Precision: 0.7392, Recall: 0.6340, F1: 0.6825\n",
      "2024-08-21 01:43:40 Epoch [196/200], Train Loss: 0.2852, Valid Loss: 0.5823, Precision: 0.7397, Recall: 0.6338, F1: 0.6827\n",
      "2024-08-21 01:43:43 Epoch [197/200], Train Loss: 0.2870, Valid Loss: 0.5833, Precision: 0.7397, Recall: 0.6341, F1: 0.6828\n",
      "2024-08-21 01:43:47 Epoch [198/200], Train Loss: 0.2861, Valid Loss: 0.5829, Precision: 0.7397, Recall: 0.6340, F1: 0.6828\n",
      "2024-08-21 01:43:50 Epoch [199/200], Train Loss: 0.2838, Valid Loss: 0.5831, Precision: 0.7399, Recall: 0.6344, F1: 0.6831\n",
      "2024-08-21 01:43:54 Epoch [200/200], Train Loss: 0.2846, Valid Loss: 0.5837, Precision: 0.7398, Recall: 0.6343, F1: 0.6830\n"
     ]
    }
   ],
   "source": [
    "with open(args.feature_file, 'r') as f:\n",
    "    feature_dict = json.load(f)\n",
    "\n",
    "with open(args.reuse_rate_file, 'r') as f:\n",
    "    reuse_rate_dict = json.load(f)\n",
    "    \n",
    "P = PassREfinder(feature_dict, reuse_rate_dict, args)\n",
    "\n",
    "P.print_graph()\n",
    "\n",
    "train_loader_list = P.get_train_data_loader_list()\n",
    "train_nfeat_list = P.pop_train_node_feature()\n",
    "\n",
    "valid_loader = P.get_data_loader('valid')\n",
    "valid_nfeat = P.pop_node_feature('valid')\n",
    "\n",
    "client_list = []\n",
    "for i in range(args.nclient):\n",
    "    client_list.append(Client(train_loader_list[i], train_nfeat_list[i], args))\n",
    "train(client_list, valid_loader, valid_nfeat, args)\n",
    "# evaluate(model, test_loader, test_nfeat, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74c32ac-bf3e-45ab-bdb7-3530d8c0bff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "passrefinder",
   "language": "python",
   "name": "passrefinder"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
