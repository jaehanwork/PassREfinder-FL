{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e94e028-9098-4d66-a008-e895ac8858f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "import dgl\n",
    "from datetime import datetime\n",
    "\n",
    "from src import *\n",
    "from pprint import pprint\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "data_dir = './data_passrefinder-p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e4eaca-2e0c-40f8-8501-8e1b37d03c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(feature_file='./data_passrefinder-p/data/feature_dict.json', reuse_rate_file='./data_passrefinder-p/data/reuse_rate_dict.json', agg_type='no_hidden', nclient=10, dropout=0.5, random_seed=42, relu=0.2, reuse_th=0.5, train_batch_size=2048, eval_batch_size=2048, embed_size=1024, hidden_size=1024, gnn_depth=2, max_lr=0.001, warmup=0.02, max_epoch=100, device=0)\n"
     ]
    }
   ],
   "source": [
    "from argparse import ArgumentParser\n",
    "parser = ArgumentParser()\n",
    "\n",
    "import argparse\n",
    "from pprint import pprint\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Parser for model configuration\")\n",
    "\n",
    "parser.add_argument('--feature_file', type=str, default=f\"{data_dir}/data/feature_dict.json\", help='feature json file')\n",
    "parser.add_argument('--reuse_rate_file', type=str, default=f\"{data_dir}/data/reuse_rate_dict.json\", help='reuse rate json file')\n",
    "# parser.add_argument('--setting', type=str, required=True, help='graph learning setting: inductive/transductive')\n",
    "# parser.add_argument('--model_path', type=str, required=True, default=\"./model/\", help='model file path')\n",
    "parser.add_argument('--agg_type', type=str, default=\"no_hidden\", help='aggregation type')\n",
    "parser.add_argument('--nclient', type=int, default=10, help='number of clients')\n",
    "# parser.add_argument('--valid', type=float, default=0.2, help='split ratio of validation set')\n",
    "# parser.add_argument('--test', type=float, default=0.2, help='split ratio of test set')\n",
    "parser.add_argument('--dropout', type=float, default=0.5, help='dropout ratio')\n",
    "parser.add_argument('--random_seed', type=int, default=42, help='random seed for initialization')\n",
    "parser.add_argument('--relu', type=float, default=0.2, help='ReLU threshold')\n",
    "parser.add_argument('--reuse_th', type=float, default=0.5, help='threshold for reuse')\n",
    "parser.add_argument('--train_batch_size', type=int, default=2048, help='batch size for training')\n",
    "parser.add_argument('--eval_batch_size', type=int, default=2048, help='batch size for evaluation')\n",
    "parser.add_argument('--embed_size', type=int, default=1024, help='size of the embedding layer')\n",
    "parser.add_argument('--hidden_size', type=int, default=1024, help='size of the hidden layer')\n",
    "parser.add_argument('--gnn_depth', type=int, default=2, help='depth of the GNN')\n",
    "parser.add_argument('--max_lr', type=float, default=0.001, help='maximum learning rate')\n",
    "parser.add_argument('--warmup', type=float, default=0.02, help='warmup ratio for learning rate')\n",
    "parser.add_argument('--max_epoch', type=int, default=100, help='maximum number of epochs')\n",
    "# parser.add_argument('--early_stop', type=int, default=40, help='early stopping epochs')\n",
    "parser.add_argument('--device', type=int, default=0, help='GPU ID')\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "pprint(args)\n",
    "\n",
    "torch.manual_seed(args.random_seed)\n",
    "torch.cuda.manual_seed(args.random_seed)\n",
    "dgl.seed(args.random_seed)\n",
    "np.random.seed(args.random_seed)\n",
    "random.seed(args.random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "826581e9-1e24-4e6f-91c2-ae90530983c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing graph...\n",
      "\u001b[FConstructing graph... Done\n",
      "Splitting graph...\n",
      "\u001b[FSplitting graph... Done\n"
     ]
    }
   ],
   "source": [
    "with open(args.feature_file, 'r') as f:\n",
    "    feature_dict = json.load(f)\n",
    "\n",
    "with open(args.reuse_rate_file, 'r') as f:\n",
    "    reuse_rate_dict = json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "g = construct_graph(feature_dict, reuse_rate_dict, args.reuse_th)\n",
    "g_dict, node_set_list, target_eids_dict = graph_split_FL(g, args.nclient, args.random_seed)\n",
    "\n",
    "\n",
    "\n",
    "# train_loader_list = []\n",
    "# for g, nodes in zip(g_split['train'], node_split['train']):\n",
    "#     train_loader_list.append(get_data_loader(g, nodes, args.train_batch_size, args.gnn_depth, suffle=True))\n",
    "# train_nfeat_list = P.pop_train_node_feature()\n",
    "\n",
    "# valid_loader = get_data_loader(g_split['valid'], node_split['valid'])\n",
    "# valid_nfeat = P.pop_node_feature('valid')\n",
    "# test_loader = get_data_loader(g_split['test'], node_split['test'])\n",
    "# test_nfeat = P.pop_node_feature('test')\n",
    "\n",
    "\n",
    "P = PassREfinder_FL(g_dict, node_set_list, target_eids_dict, args)\n",
    "# P.print_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d90c2897-8561-43d0-8616-6b5191ee6575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_random(P):\n",
    "    print('Evaluating...')\n",
    "\n",
    "    node_dict = {}\n",
    "    for i, node_set in enumerate(P.node_set_list):\n",
    "        node_dict.update(dict.fromkeys(node_set.numpy().tolist(), i))\n",
    "\n",
    "    sample_size = 64\n",
    "    _reuse_rate_top_test = defaultdict(dict)\n",
    "    for id1, id2, score in zip(P.g_dict['test'].edges(etype='reuse')[0].tolist(), P.g_dict['test'].edges(etype='reuse')[1].tolist(), P.g_dict['test'].edata['rate'][('website', 'reuse', 'website')].tolist()):\n",
    "        if node_dict[id1] != node_dict[id2]:\n",
    "            _reuse_rate_top_test[id1][id2] = score\n",
    "    \n",
    "    reuse_rate_top_test = {}\n",
    "    for id1, id2_list in _reuse_rate_top_test.items():\n",
    "        if len(id2_list) >= sample_size:\n",
    "            id2_list = {k: v for k, v in sample(id2_list.items(), sample_size)}\n",
    "            id2_list = {k: v for k, v in sorted(id2_list.items(), key=lambda x: x[1], reverse=True)}\n",
    "            reuse_rate_top_test[id1] = id2_list\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pair_to_score = defaultdict(dict)\n",
    "        \n",
    "        for input_nodes, edge_sub, blocks in tqdm(P.test_loader):\n",
    "            batch_inputs, batch_labels = load_subtensor(*P.test_nfeat, edge_sub, input_nodes, 'cpu')\n",
    "            blocks = [block.int().to('cpu') for block in blocks]\n",
    "\n",
    "            edge_tensor = P.g_dict['test'].find_edges(edge_sub.edata['_ID'][('website', 'reuse', 'website')].detach().cpu().numpy(), etype='reuse')\n",
    "            edge_list = [(src, dst) for src, dst in zip(edge_tensor[0].tolist(), edge_tensor[1].tolist())]\n",
    "            \n",
    "            for edge in edge_list:\n",
    "                pair_to_score[edge[0]][edge[1]] = random.random()\n",
    "\n",
    "    result = {}\n",
    "    result['prec@k'] = evaluate_precision(pair_to_score, reuse_rate_top_test)\n",
    "    result['nDCG@k'] = evaluate_ndcg(pair_to_score, reuse_rate_top_test)\n",
    "    return result, pair_to_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61819d4c-53ea-4080-bbd4-2e11ae02ca02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1359817/2970022190.py:17: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  id2_list = {k: v for k, v in sample(id2_list.items(), sample_size)}\n",
      "100%|██████████| 511/511 [01:23<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Precision@1': 0.016654330125832718,\n",
      " 'Precision@10': 0.1567357512953368,\n",
      " 'Precision@30': 0.46778929188255614,\n",
      " 'Precision@5': 0.08031088082901554,\n",
      " 'Precision@50': 0.7824500370096225}\n",
      "{'nDCG@1': 0.5856387514090987,\n",
      " 'nDCG@10': 0.6115201959731528,\n",
      " 'nDCG@30': 0.6589766376870815,\n",
      " 'nDCG@5': 0.6005190864736963,\n",
      " 'nDCG@50': 0.7125844666478005}\n",
      "CPU times: user 19min 7s, sys: 7.23 s, total: 19min 15s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_dir = \"data_passrefinder-p/output/fl_passrefinder/client_10/2025-03-28 13:04:27\"\n",
    "P.model = load_model(os.path.join(model_dir, 'model.pt'), P.model)\n",
    "result, pair_to_score = evaluate_random(P)\n",
    "\n",
    "pprint(result['prec@k'])\n",
    "pprint(result['nDCG@k'])\n",
    "\n",
    "\n",
    "\n",
    "# with open(os.path.join(output_dir, 'eval_results.json'), 'w') as f:\n",
    "#     json.dump(result, f)\n",
    "# with open(os.path.join(output_dir, 'pair_to_score.json'), 'w') as f:\n",
    "#     json.dump(pair_to_score, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ad0d0c-bf47-424f-920c-bac7f5a23ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "passrefinder",
   "language": "python",
   "name": "passrefinder"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
